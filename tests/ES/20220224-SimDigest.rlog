
R Log to Extract and Analyze Table-Cell Summaries from Jim's Simulations
========================================================================
Eric Slud,        1/25/2022

> setwd("c://EricStf/CensusProj/DiffPrivacy")
> attach("bottomUp-forEric.RData")
> objects(2)
[1] "A" "R"
> dimnames(A)   ### 2x2x7x3x2x43  =  7224 elements
[[1]]
[1] "own" "rnt"

[[2]]
[1] "mal" "fem"

[[3]]
[1] "wh"   "bl"   "as"   "aian" "pac"  "oth"  "twp" 

[[4]]
[1] "0-17"  "18-62" "62p"  

[[5]]
[1] "hisp"    "nonhisp"

[[6]]
 [1] "tr1"  "tr2"  "tr3"  "tr4"  "tr5"  "tr6"  "tr7"  "tr8"  "tr9"  "tr10"
[11] "tr11" "tr12" "tr13" "tr14" "tr15" "tr16" "tr17" "tr18" "tr19" "tr20"
[21] "tr21" "tr22" "tr23" "tr24" "tr25" "tr26" "tr27" "tr28" "tr29" "tr30"
[31] "tr31" "tr32" "tr33" "tr34" "tr35" "tr36" "tr37" "tr38" "tr39" "tr40"
[41] "tr41" "tr42" "tr43"

> dim(R)
[1] 7224   12   20       ## all cells, 12 successive workload sims, 20 runs each

## All 12 runs should have the same Laplace noise added
#  sum(c(A)) = 14480, avg. pop count of 20 per cell, with lots of zeroes.
#   so assume  A  is the array of "true " cell counts
#    and   R  the arrays of sim-by-run cell estimates


> summary(c(A))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      0       0       0      20       5     467 
> summary(c(R[,1,]))
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-419.301   -0.872    2.049   20.000    8.173  857.745 

## This is completely weird: it says that the sim1 estimates include 
#    some huge negative value(s).

> c(sum(c(R[,1,] < -100), sum(c(R[,1,] > 100))

>  c(sum(c(R[,1,] < -100)), sum(c(A > 450)), sum(c(R[,1,] > 450)))
[1]  6  4 66

> hist(c(log(1+A)))$counts   ## intervals [k/2, (k+1)/2]
 [1] 3630  834  684  442  349  272  122  130  238  142  260  103   18

> summary(c(R[,1,]-c(A)))
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-536.3009   -2.3085   -0.0041    0.0000    2.2951  857.7455 

### How can there be cells so negative in R[,1,] ???

> apply(R < -50,2,sum)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
    7    13     1     0     0     1     0     0     0     0     0     0 
> apply(R < -100,2,sum)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
    6     0     0     0     0     0     0     0     0     0     0     0 

## 6 cells have value < -100  in Sim1, which is presumably just the sim with
##    iid Laplace noise added. Each 0 cell would have probability 0.5*exp(-100/b)
##    of being < -100. If 6 were the expected number we would have 
#      6 = 3630*20*0.5*exp(-100*epsilon), or epsilon= log(3630*20*0.5/6)/100 = .087
## Why are we taking epsilon so small ?

detach(); attach("topDown-forEric.RData")
## A same as before

> summary(c(R[,1,]))
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-489.3590   -0.9254    2.0116   20.0002    8.1286  955.5997 

## Very similar. So we have a really small epsilon, b >~ 11 and 
# P(X < -100) = 0.5*exp(-9) = 6.17e-5 
# and in 3630*20 trials this would happen ~ Poisson(4.5) times ...

#------------------------------------------------------------------
# RESUME 1/27 TO EXAMINE THE P1 regression outputs with additional margins

> apply(R < -50,2,sum)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
    7    13     1     0     0     1     0     0     0     0     0     0 

> round(apply(R[,1:6,]-c(A), 2, function(tab) summary(c(tab))),2)
           sim1    sim2   sim3   sim4   sim5   sim6
Min.    -536.30 -123.78 -62.69 -41.77 -45.01 -51.21
1st Qu.   -2.31   -2.33  -2.38  -2.54  -2.51  -2.51
Median     0.00    0.01   0.03   0.00   0.02   0.01
Mean       0.00    0.00   0.00   0.00   0.00   0.00
3rd Qu.    2.30    2.35   2.43   2.54   2.55   2.55
Max.     857.75  151.18  47.57  43.91  50.02  47.21

## This exhibit makes it seem that wherever there are (more than a few) 
#  large negative cells, there are not large discrepancies to worry about.

> apply(R < -40,2,sum)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
    7    28     8     0     1     4     0     1     1     0     2     1 
> apply(R < -30,2,sum)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
   18   100    63    31    19    32    23    20    22    25    27    32 
> 

> tmp = which(R < -50, arr.ind=T)
  cbind(tmp,A=A[tmp[,1]])
      dim1 dim2 dim3   A
 [1,]  488    2    1  13
 [2,] 7202    1    2 109
 [3,]  486    2    2  10
 [4,] 1659    1    3 109
 [5,] 4681    2    4  17
 [6,] 7202    1    6 109
 [7,]  828    2    6   1
 [8,] 7202    1    7 109
 [9,]  486    2    7  10
[10,] 7175    1    8 117
[11,] 1658    1    9 115
[12,] 7202    1    9 109
[13,] 5865    2   10   0
[14,]  146    2   11  19
[15,] 6686    3   12   1
[16,] 5521    2   13  13
[17,] 5354    2   14  15
[18,] 5187    2   15  18
[19,] 4226    6   15   0
[20,]  145    2   19  19
[21,] 6195    2   19  17
[22,] 5018    2   20  12

### This is very striking: a couple of the same A cells with positive entries
##     have estimated cell values having very negative values in at least two runs!
##  The cell 7202 with A entry 109 generated very negative R's 
#      in 5 separate runs: 2,3,6,7,9. I think is the "puzzler" you found.

## Cell 7202 within 7224 found as follows
> Aaux[7202]=Aaux[7202]+runif(1)*1e-5
> which(Aaux %%1 > 0, arr.ind=T)
    dim1 dim2 dim3 dim4 dim5 dim6
rnt    2    1    2    3    2   43

## This cell with A count 109, has estimated R count < -50 in 5 of the 20 runs, 
##    occurring in sim1 but no other sims

> R[7202,1,]
 [1]  117.79262 -221.45814  117.64706  115.47868  107.69223 -211.66173
 [7] -177.31590  110.13834 -205.30066  105.87385  112.03005  110.45235
[13]  107.37750   57.35031  111.20798  108.73922  111.85960  116.45103
[19]  108.17760  112.95658

> aux = which(abs(R - c(A)) > 100, arr.ind=T) ### 38 occurrences, all in sims 1,2

> hist(log(1+abs(R[,1]-c(A)), prob=T)

>  hist(sign(R[,1,]-c(A))*log(1+abs(R[,1,]-c(A))), prob=T)  
    ## so remarkably symmetric bimodal, that this cannot be accidental !

par(mfrow=c(2,2))
for(i in c(1,2,4,6))  hist(sign(R[,i,]-c(A))*log(1+abs(R[,i,]-c(A))), 
                         xlim=c(-4,4), xlab="Discrepancy", prob=T,
                         main = paste0("log(1+D) times sign, sim ",i))  
   ## The tails are not becoming thinner, and that slight thickening may 
  #       be the reason that sum(abs) or SSQ metrics actually 
  #       get a little worse with increasing sim index.

for(i in c(3,5,9,12))  hist(sign(R[,i,]-c(A))*log(1+abs(R[,i,]-c(A))), 
                         xlim=c(-4,4), xlab="Discrepancy", prob=T,
                         main = paste0("log(1+D) times sign, sim ",i))  

   ### THIS IS THE SAVED FIGURE "DiscrepancyPic1.pdf"


> round(sqrt(apply(R - c(A), 2, function(dif) mean(dif^2))),2)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
 6.04  6.32  5.45  5.42  5.41  5.38  5.36  5.37  5.41  5.39  5.42  5.44 
     ### I am not sure if we looked at this: it seems that root-mean-squared
   ## discrepancies decrease rapidly and level off after an initial 
  #   (mysteriousd) increase between sim1 and sim2.

> round(apply(R - c(A), 2, function(dif) mean(abs(dif))),2)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
 3.36  3.64  3.68  3.76dim  3.75  3.74  3.73  3.74  3.75  3.75  3.76  3.77 
## but for mean sbsolute discrepancy, there is pretty steady increase 
#   and leveling off except for noise. I think this must be due to the 
#   nature of the optimization: we are optimizing an expression consisting
#   of this mean absolute difference plus an additional set of terms.

#---------------------------------------------------------------------
# Compare the last set of sim-level comparisons with 
#   the same metrics for the topDown:

detach(); attach("topDown-forEric.RData")

> round(sqrt(apply(R - c(A), 2, function(dif) mean(dif^2))),2)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
 6.61  6.39  6.38  6.38  6.31  6.21  6.15  6.21  6.02  5.71  5.72  5.40 
###  topdown behave mich better, more what we expected !!!

> round(apply(R - c(A), 2, function(dif) mean(abs(dif))),2)
 sim1  sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12 
 3.38  3.38  3.42  3.44  3.59  3.60  3.59  3.72  3.69  3.67  3.92  3.76 
## but again (for the same reason) greater workload generally implies worse
#   mean absolute discrepancy ...

##======================================================================
# Maybe overall the lack of better leveling-off behavior may be due 
#     to the large noise (or too-small epsilon).


##--------------------------------------------------------------2/16/22
# Try again with new files sent this week (Mon 2/14)
## Workspace will again be "SimDigest.RData"

> attach("bottomUp-forEric.RData")
> objects(2)
[1] "A" "R"
> dim(A)
[1]  2  2  7  3  2 43     ## product = 7224
> dim(R)
[1] 7224   11   20        ## 11 sims, 20 reps
> dimnames(A)
[[1]]
[1] "own" "rnt"

[[2]]
[1] "mal" "fem"

[[3]]
[1] "wh"   "bl"   "as"   "aian" "pac"  "oth"  "twp" 

[[4]]
[1] "0-17"  "18-62" "62p"  

[[5]]
[1] "hisp"    "nonhisp"

[[6]]
 [1] "tr1"  "tr2"  "tr3"  "tr4"  "tr5"  "tr6"  "tr7"  "tr8"  "tr9"  "tr10"
[11] "tr11" "tr12" "tr13" "tr14" "tr15" "tr16" "tr17" "tr18" "tr19" "tr20"
[21] "tr21" "tr22" "tr23" "tr24" "tr25" "tr26" "tr27" "tr28" "tr29" "tr30"
[31] "tr31" "tr32" "tr33" "tr34" "tr35" "tr36" "tr37" "tr38" "tr39" "tr40"
[41] "tr41" "tr42" "tr43"

> dimnames(R)[[1]]
 [1] "sim2"  "sim3"  "sim4"  "sim5"  "sim6"  "sim7"  "sim8"  "sim9"  "sim10"
[10] "sim11" "sim12"     ## NB omits initial sim1 with only detailed cells and no margins

> summary(c(R[,1,]))
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-36.0800  -0.1458   1.2106  20.0006   5.6947 471.2343 
> summary(c(A))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.      ## comparison much more reasonable now.
      0       0       0      20       5     467 

### Next explore R-A differences ... THIS IS BOTTOM-UP ANALYSIS

> summary(c(R[,1,])-c(A))
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-53.07999  -0.83033   0.00231   0.00061   0.82869  48.35743 
> hist(c(R[,1,])-c(A), nclass=50)   ## very peaked, very long-tailed

> round(apply(apply(R-c(A), 2:3, mean), 1, summary),5)
            sim2     sim3     sim4     sim5     sim6     sim7     sim8     sim9
Min.    -0.00205 -0.00205 -0.00495 -0.00075 -0.00075 -0.00099 -0.00028 -0.00026
1st Qu. -0.00028 -0.00028 -0.00265 -0.00011 -0.00015 -0.00021 -0.00019 -0.00009
Median   0.00082  0.00082 -0.00169  0.00015  0.00009  0.00001  0.00000 -0.00005
Mean     0.00061  0.00061 -0.00159  0.00021  0.00015  0.00008  0.00000  0.00003
3rd Qu.  0.00171  0.00171 -0.00056  0.00056  0.00027  0.00046  0.00018  0.00008
Max.     0.00347  0.00347  0.00176  0.00110  0.00134  0.00119  0.00041  0.00045
           sim10    sim11    sim12
Min.    -0.00037 -0.00029 -0.00044
1st Qu. -0.00007 -0.00007 -0.00017
Median   0.00005  0.00002 -0.00004
Mean     0.00006  0.00003 -0.00004
3rd Qu.  0.00022  0.00015  0.00006
Max.     0.00057  0.00029  0.00040

## This is an interesting table: not that we are looking at means across simulations at this point, not yet assessing variability. The anomaly is what happens at sim4, in which the upper and lower tails (of the means across simulations) are both pulled sharply to the left at sim4. Then at sim8 and beyond, both tails are pulled in. These errors plus and minus are both very small!

## The next table gives summaries of the standard deviations across 7224 cells, not what we typically look at. But that is extremely stable and hardly comes down. 

## The small size of these numbers says we may have epsilon too large ?!

> round(apply(apply(R-c(A), 2:3, sd), 1, summary),3)
         sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12
Min.    2.019 1.911 1.883 1.870 1.876 1.896 1.894 1.885 1.917 1.888 1.895
1st Qu. 2.155 1.947 1.922 1.929 1.915 1.925 1.906 1.920 1.929 1.915 1.926
Median  2.253 1.963 1.933 1.959 1.929 1.936 1.927 1.935 1.950 1.942 1.942
Mean    2.237 1.962 1.941 1.957 1.932 1.940 1.926 1.936 1.946 1.939 1.944
3rd Qu. 2.281 1.975 1.966 1.984 1.941 1.953 1.944 1.952 1.960 1.955 1.968
Max.    2.432 2.018 1.990 2.012 2.016 1.988 1.971 1.998 1.973 1.996 2.009

> boxplot(t(apply(R-c(A), 2:3, sd)))  ## very rapid settling down: 
                  # the trend seems to be pure noise from sim6 on

## another view: take sd's only across runs, and then make boxplots of those by sim

> round(apply(apply(R-c(A), 1:2, sd), 2, summary),3)
          sim2  sim3  sim4  sim5  sim6  sim7  sim8  sim9 sim10 sim11 sim12
Min.     0.455 0.455 0.665 0.696 0.623 0.666 0.716 0.511 0.455 0.589 0.731
1st Qu.  1.366 1.432 1.522 1.529 1.520 1.524 1.515 1.520 1.528 1.522 1.521
Median   1.617 1.737 1.814 1.827 1.814 1.816 1.806 1.810 1.823 1.819 1.828
Mean     1.869 1.822 1.873 1.888 1.869 1.876 1.862 1.871 1.882 1.875 1.879
3rd Qu.  1.959 2.113 2.156 2.177 2.159 2.174 2.150 2.161 2.165 2.161 2.172
Max.    13.200 5.128 4.757 4.936 4.399 4.749 4.258 5.059 4.518 4.554 5.329

> boxplot(apply(R-c(A), 1:2, sd)) ## These are something like the boxplots 
   ## we produced before; but the overall sd numbers are small now!
   ## and remarkably, only the upper tail comes down, and for these bottom-up sims
   ## the settling-down seems to occur somewhere in the range sim4 to sim6.

## we need a different view to look at marginals
## Here is a little function to do it.

> margView = function(margnums, r, a, opt="c") {
     ## margnums is a subset of the 1:6 marginals:
    ## then we use "apply" to collect those marginals and take SD's
    ## if opt="c" SDs are taken across cells; if opt="r", across runs
     aux = array(R-c(A), c(dim(A),dim(R)[2:3]))
     tmptab = apply(aux, c(margnums, length(dim(A))+(1:2)),sum)
     ndim = length(margnums)+2
     if(opt=="c")  {
          boxplot(t(apply(tmptab,c(ndim-1,ndim),sd))) 
     } else {
          tmptab2 = array(tmptab, c(prod(dim(A)[margnums]),
             dim(R)[2:3]))
          boxplot(apply(tmptab2, 1:2, sd)) }
     }

### Still testing this ...

> margView(1:2,R,A,"c")
> margView(1:2,R,A,"r")
> margView(c(1,6),R,A,"r")


### Still need to process the top-down ... THIS IS WHERE WE LEFT IT THIS MORNING
> detach()
> attach("topDown-forEric.RData")
> detach()
  attach("bottomUp-forEric.RData")

## want to check that the sim12 data are identical in the topDown and bottom
> identical(A,A.top)
[1] TRUE
[1] 7224   11   20
> identical(R[,11,],R.top[,11,])
[1] TRUE
> rm(A.top)

> dev.new()
  margView(1:6,R,A,"r")

## The scale of errors in sim2 is VERY different for topDown (with 14 cells 
##   showing cross.rep sd's of R[,1,]-c(A) > 15) and bottomUp (with largest sd < 15)

> summary(apply(R[,1,]-c(A), 1, sd))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.4545  1.3663  1.6172  1.8685  1.9587 13.2001        ### bottomUp

>  summary(apply(R.top[,1,]-c(A), 1, sd))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.4545  1.3447  1.5828  1.6909  1.8699 50.2764        ### topDown

> bad.top = which(apply(R.top[,1,]-c(A), 1, sd) > 30)   ## 11 cases
> round(R.top[bad.top,1,],2)
        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]  [,10]  [,11]
 [1,]  20.25  23.51  24.08  22.76  25.18  23.27  23.75  22.74  20.78  23.53  24.60
 [2,]  21.79  26.14  22.32 -95.70  23.69  23.34  23.69  25.34  23.53  25.26  22.06
 [3,]   1.12  -0.84  -2.91  -0.06   3.53 151.02   8.45   2.83   0.09  -3.39   1.07
 [4,]  -0.13   1.45   2.37  -0.97 219.30   1.00   0.11   2.10   3.13   1.05  59.30
 [5,]   1.71 100.27   2.43   4.47   3.92   2.61   0.33   2.98   2.02  45.70   2.58
 [6,] 115.04 114.43 111.76 113.44 -51.00 113.48 109.60 110.46 113.14 111.41 113.90
 [7,] 104.57 106.16  27.45 108.15 106.99 104.07 106.57 105.64 105.64 105.97 106.36
 [8,] 166.57  -0.12  -0.55  -2.05  -0.08  -0.69  -4.00   0.06   2.68  -0.95  -1.51
 [9,]   0.82  -0.80   1.22   1.27   1.13   1.31  -0.03  -0.06  -0.13   2.57  93.37
[10,]   0.26  75.73   4.82   2.27   0.85   1.40  48.72   1.41 110.51   0.43   0.47
[11,]   0.41   1.03  -0.57   0.00  -0.69  89.18   1.07   0.52   0.29  99.67   1.62
       [,12]  [,13]   [,14]  [,15]  [,16]  [,17]   [,18]  [,19]  [,20]
 [1,]  25.21  21.67   23.56  23.44  23.52  22.73 -129.03  21.98  16.25
 [2,]  23.17  22.86 -107.02  25.11  21.92  22.26   24.81  21.27  23.34
 [3,]   1.30   1.47    2.50 134.13   0.65  -0.39   -0.18  -1.39  -0.48
 [4,]   0.22   4.47   -0.01   0.00  48.69   1.83    1.06   1.35   0.22
 [5,]  94.28   3.02    2.51   2.59   1.96   5.70   -3.63   3.44   2.89
 [6,] 112.83 111.20  115.55 113.99 -39.75 112.68  115.65 114.80 115.83
 [7,] 109.93 104.59   19.33  -0.73 105.31  56.73  106.92 105.27 106.86
 [8,]   0.93  -0.60   -0.27  -0.23   0.70  -2.27    6.10  -0.02  -1.20
 [9,]  -2.81 129.91   -0.54   0.17   1.85   0.43   -0.71  -0.06   1.25
[10,]   1.45   1.02    1.75  -3.05   2.34  -2.36   -0.24   0.65  -0.15
[11,]  -2.24   0.60   -1.41  -2.17  -0.93   1.55    9.64  -0.16  62.78

## In all these cases, there are one or two rep's out if 20 that result in hugely 
#   estimated R.top[bad.top,1,] values

> round(apply(R.top[bad.top,,]-c(A)[bad.top], 1:2, sd),2)
       sim2  sim3  sim4  sim5 sim6 sim7 sim8 sim9 sim10 sim11 sim12
 [1,] 34.00  2.00 16.24  6.81 2.00 2.07 2.00 2.00  2.00  2.00  2.20
 [2,] 38.48  1.49 10.34  6.49 1.49 1.81 1.49 3.59  1.49  2.69  1.62
 [3,] 43.81 24.11 18.65  5.11 1.77 1.77 1.77 1.77  6.73  1.77  1.63
 [4,] 50.28 26.80 26.85  3.93 1.15 1.15 1.55 1.12  1.19  1.45  1.40
 [5,] 30.11  6.60  2.23  2.23 2.23 2.23 1.98 2.23  2.23  1.79  2.50
 [6,] 48.90  1.76  5.63  4.60 4.61 1.76 2.56 1.76  1.76  2.41  1.71
 [7,] 34.39 20.40 12.69 11.51 1.36 1.36 2.75 3.29  1.36  2.03  1.58
 [8,] 37.35 10.07  2.01  2.01 2.71 2.81 2.01 2.03  2.01  2.24  2.46
 [9,] 34.77 18.20 15.62  1.80 5.48 1.66 1.92 1.83  1.66  1.65  1.68
[10,] 30.17 25.69 14.11  1.70 2.07 1.94 1.70 1.86  1.70  2.18  2.53
[11,] 31.25 21.95  1.24  1.23 1.24 1.24 1.25 1.44  2.37  1.52  1.75  ## DRAMATIC!

> round(apply(R[bad.top,,]-c(A)[bad.top], 1:2, sd),2)
        sim2 sim3 sim4 sim5 sim6 sim7 sim8 sim9 sim10 sim11 sim12
 [1,]  2.00 2.00 1.22 1.68 1.24 1.28 2.29 1.36  2.22  2.12  2.20
 [2,]  1.49 2.86 1.52 1.69 1.80 1.56 2.44 1.46  1.92  1.49  1.62
 [3,]  9.52 2.21 1.58 1.91 2.19 2.04 2.58 2.15  2.15  2.16  1.63
 [4,]  4.71 1.50 1.57 1.15 1.69 1.80 1.35 1.10  1.15  2.57  1.40
 [5,]  2.82 2.04 2.22 2.05 1.85 2.25 1.67 1.96  2.12  2.28  2.50
 [6,]  9.93 1.76 3.08 2.67 1.83 1.89 2.19 1.64  1.68  2.37  1.71
 [7,]  5.98 3.73 1.93 1.61 1.37 2.68 1.94 2.52  1.72  2.38  1.58
 [8,]  2.01 2.66 2.55 2.59 2.10 2.13 2.47 2.41  2.41  2.21  2.46
 [9,]  4.95 1.48 2.51 1.60 1.95 1.70 1.77 1.73  1.72  1.69  1.68
[10,]  2.67 1.69 1.66 2.02 2.25 2.38 1.73 1.91  1.97  1.65  2.53
[11,] 10.00 1.67 1.81 2.02 1.70 1.25 1.64 1.45  2.39  1.71  1.75
     ### this suggests that all the anomalies are due to really large 
#   Laplace noise added to marginal in State and County Geo marginals

> cbind(bad.Aind, cell=A[bad.Aind])
      dim1 dim2 dim3 dim4 dim5 dim6 cell
 [1,]    2    1    2    3    2   28   23
 [2,]    1    2    2    3    2   28   23
 [3,]    2    2    5    3    2   28    0
 [4,]    1    2    6    3    2   28    1
 [5,]    2    2    6    3    2   28    3
 [6,]    1    2    2    3    2   43  114
 [7,]    2    2    2    3    2   43  106
 [8,]    2    1    4    3    2   43    0
 [9,]    2    1    6    3    2   43    0
[10,]    1    2    6    3    2   43    0
[11,]    2    2    6    3    2   43    0

> bad.top
 [1] 4682 4683 4696 4699 4700 7203 7204 7210 7218 7219 7220

#--------------------------------------------------------